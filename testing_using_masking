import numpy as np
from stable_baselines3 import A2C
from setting_the_environment import AUVEnvironment  



# Load the pre-trained model
model_path = "training/saved_models/A2C_model_version_after_masking"
model = A2C.load(model_path)

# Create the environment
env = AUVEnvironment()

# Test the trained model for 3 episodes
num_episodes = 2
for episode in range(num_episodes):
    obs = env.reset()
    done = False
    total_reward = 0
    while not done:
        auv_position = env.auv_position
        # Predict action using the model
        action, _ = model.predict(obs, deterministic=False)
        obs, reward, done, _ = env.step(action)  # Take action in the environment
        total_reward += reward
        # Optionally, render the environment
        env.render()
        # Print AUV position
        print("AUV position:", env.auv_position)
        print("Action:", action)
        print("reward",reward)
    print(f"Episode {episode + 1}: Total reward = {total_reward}")

# Close the environment
env.close()
