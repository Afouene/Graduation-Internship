from stable_baselines3 import A2C
from stable_baselines3.common.evaluation import evaluate_policy
from setting_the_environment import AUVEnvironment  
from stable_baselines3.common.env_util import make_vec_env

from stable_baselines3.common.sb2_compat.rmsprop_tf_like import RMSpropTFLike
import matplotlib.pyplot as plt
import os 
import numpy as np
env = AUVEnvironment()

model = A2C("MlpPolicy", env, verbose=1,ent_coef=0.1)
model.learn(total_timesteps=10000)
model_path=os.path.join("training\saved_models","model_version_5")
model.save(model_path)
#mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=50, deterministic=False)
ep_rewards = [ep_info['r'] for ep_info in model.ep_info_buffer]
print("episode",ep_rewards)
"""# Plot the learning curve
plt.plot(ep_rewards)
plt.xlabel("Training Episode")
plt.ylabel("Reward")
plt.title("A2C Learning Curve")
plt.grid(True)
plt.show()"""